{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c0d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31da569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import zoom\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import types\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import torchio as tio\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "from models.convmixer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0a9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 551"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e96349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# control randomness\n",
    "def set_seed(random_seed=551):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7a34af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_dir, label_dir, label_name, std=False, norm=True):\n",
    "    df = pd.read_csv(label_dir, index_col=0)[label_name]\n",
    "    filenames = df.index\n",
    "    images = []\n",
    "    for i, index in enumerate(filenames):\n",
    "        file_name = img_dir + index + '.npy'\n",
    "        img = np.load(file_name)\n",
    "        x, y, z = img.shape\n",
    "        if norm:\n",
    "            img = (img - img.min()) / (img.max() - img.min())\n",
    "        if std:\n",
    "            m = np.mean(img)\n",
    "            s = np.std(img)\n",
    "            img = (img - m) / s\n",
    "        img = img.reshape((1, x, y, z))\n",
    "        images.append(img)\n",
    "    return images, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f736886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation\n",
    "def get_augmentation_transform():\n",
    "    random_rotate = tio.RandomAffine(scales=(1.0, 1.0),\n",
    "                                     degrees=12,)\n",
    "    random_flip = tio.RandomFlip(axes='LR',\n",
    "                                 flip_probability=0.5)\n",
    "    random_shift = tio.RandomAffine(scales=(1.0, 1.0),\n",
    "                                    degrees=0,\n",
    "                                    translation=(20,20,20))\n",
    "    compose = tio.transforms.Compose([random_rotate, random_flip, random_shift])\n",
    "    augment = tio.transforms.OneOf([random_rotate, random_flip, random_shift, compose])\n",
    "    return augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60667d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeckDataset(Dataset):\n",
    "    def __init__(self, X=None, y=None, transform=None, lds=False, lds_kernel='gaussian', lds_ks=5, lds_sigma=2):\n",
    "        self.X = X\n",
    "        self.y = y.values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx]\n",
    "        label = np.array([self.y[idx]]).astype('float16')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return [image, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fabe692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    total_mae, total_mse = 0, 0\n",
    "    preds, truths = np.array([]), np.array([])\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(train_loader):              \n",
    "        inputs, labels = inputs.to(device, dtype=torch.float), labels.to(device, dtype=torch.float)\n",
    "        \n",
    "        # feedforward\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        pred = outputs.detach().cpu().numpy()\n",
    "        truth = labels.detach().cpu().numpy()\n",
    "        preds = np.append(preds, pred.reshape(pred.size), axis=0)\n",
    "        truths = np.append(truths, truth.reshape(truth.size), axis=0)\n",
    "        \n",
    "        # calculate loss\n",
    "        mse = criterion1(outputs, labels)\n",
    "        mae = criterion2(outputs, labels)\n",
    "        \n",
    "        # gradient initialization\n",
    "        optimizer.zero_grad()\n",
    "        # backpropagation\n",
    "        mse.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_mae += mae.data.item()\n",
    "        total_mse += mse.data.item()\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    return preds, truths, total_mse, total_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57efcecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, valid_loader):    \n",
    "    total_mae, total_mse = 0, 0\n",
    "    preds, truths = np.array([]), np.array([])\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(valid_loader):\n",
    "            inputs, labels = inputs.to(device, dtype=torch.float), labels.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            pred = outputs.detach().cpu().numpy()\n",
    "            truth = labels.detach().cpu().numpy()\n",
    "            preds = np.append(preds, pred.reshape(pred.size), axis=0)\n",
    "            truths = np.append(truths, truth.reshape(truth.size), axis=0)\n",
    "\n",
    "            mse = criterion1(outputs, labels)\n",
    "            mae = criterion2(outputs, labels)\n",
    "            \n",
    "            total_mae += mae.data.item()\n",
    "            total_mse += mse.data.item()\n",
    "        \n",
    "    return preds, truths, total_mse, total_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eb08047",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2caeb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = 'FL_WMH_VOL_icv'\n",
    "# label_name = 'FL_WMH_VOL_mL'\n",
    "# label_name = 'WMH_GRADE'\n",
    "# label_name = 'Cortical Gray Matter Total Percent Of Icv'\n",
    "# label_name = 'FL_PVWMH_VOL_icv'\n",
    "# label_name = 'FL_DWMH_VOL_icv'\n",
    "img_dir = 'img_npy/'\n",
    "label_dir = 'labels/data_975.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3175e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번 실험 고정 값\n",
    "batch_size = 2\n",
    "test_batch_size = 2\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84166bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 195, 780, 195)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "X, y = load_data(img_dir, label_dir, label_name, std=True, norm=True)\n",
    "\n",
    "# initialize seed\n",
    "set_seed()\n",
    "\n",
    "# train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# train set\n",
    "train_set = NeckDataset(X_train, y_train)\n",
    "\n",
    "# test set & loader\n",
    "test_set = NeckDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=16)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8894a4cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUjUlEQVR4nO3dfZBV1Znv8e8TQHtQBAYoo7SVJo7xIogo4FUJVtSILRC0Ijo4Nxm1iCTIpJxMwoi3UhJT3gpTWIKQiRQZqWuMjhJ8o6I14guUMUgYQIgiTACLYGMyNERQYvCKrPtHbylAoN/O6WOv/n6qunrvtdde59lN8zu719lnn0gpIUnKy2cqXYAkqfQMd0nKkOEuSRky3CUpQ4a7JGWoc6ULAOjdu3eqqampdBmS1K6sWrVqR0qpz5G2fSrCvaamhpUrV1a6DElqVyLi90fb5rSMJGXIcJekDBnukpShT8Wcu6T25cMPP6Suro69e/dWupQOoaqqiurqarp06dLkfQx3Sc1WV1dHt27dqKmpISIqXU7WUkrs3LmTuro6+vXr1+T9nJaR1Gx79+6lV69eBnsbiAh69erV7L+SDHdJLWKwt52W/KwNd0nKkHPuklqtZurTJR1vy/TRx9y+a9cuHn74YW655ZZmjz1q1CgefvhhevTocdQ+d9xxBxdffDFf/vKXmz1+azz55JN84Qtf4Kyzzmr1WO0+3JvzS9XYL4yk9mHXrl385Cc/OWK479u3j86djx5tzzzzTKPj//CHP2xVfS315JNPMmbMmJKEu9MyktqdqVOnsnnzZgYPHsyUKVNYunQpI0aMYOzYsQeC8eqrr2bIkCEMGDCAefPmHdi3pqaGHTt2sGXLFvr378/NN9/MgAEDGDlyJH/5y18AuPHGG1m4cOGB/tOmTeO8887j7LPPZsOGDQDU19dz+eWXM2DAAL7xjW/wuc99jh07dhxS50cffcSNN97IwIEDOfvss5k5cyYAmzdvpra2liFDhjBixAg2bNjAsmXLWLRoEVOmTGHw4MFs3ry5VT8jw11SuzN9+nROP/101qxZw4wZMwBYvXo19957L7/73e8AmD9/PqtWrWLlypXMnj2bnTt3fmKcjRs3MnnyZNatW0ePHj147LHHjvh4vXv3ZvXq1UyaNIm7774bgDvvvJNLL72UdevWMW7cOLZu3fqJ/dasWcO2bdt4/fXXee2117jpppsAmDhxInPmzGHVqlXcfffd3HLLLVx00UWMHTuWGTNmsGbNGk4//fRW/Yza/bSMJAGcf/75h1wHPnv2bJ544gkA3nrrLTZu3EivXr0O2adfv34MHjwYgCFDhrBly5Yjjv3Vr371QJ/HH38cgJdffvnA+LW1tfTs2fMT+33+85/nzTff5Nvf/jajR49m5MiR7Nmzh2XLlnHttdce6PfBBx+07KCPwXCXlIUTTjjhwPLSpUt5/vnneeWVV+jatStf+tKXjnid+PHHH39guVOnTgemZY7Wr1OnTuzbt6/JNfXs2ZO1a9fy7LPPMnfuXBYsWMCsWbPo0aMHa9asafI4LeG0jKR2p1u3brz33ntH3b5792569uxJ165d2bBhA8uXLy95DcOHD2fBggUALF68mHfeeecTfXbs2MH+/fu55ppruOuuu1i9ejUnnXQS/fr14xe/+AXQ8A7UtWvXNum4msMzd0mt1tZXovXq1Yvhw4czcOBArrzySkaPPvTxa2trmTt3Lv379+fMM8/kggsuKHkN06ZN4/rrr+fBBx/kwgsv5LOf/SzdunU7pM+2bdu46aab2L9/PwA/+tGPAHjooYeYNGkSd911Fx9++CHjx4/nnHPOYfz48dx8883Mnj2bhQsXtmrePVJKLT+6Ehk6dGhq6Yd1eCmk1PbWr19P//79K11GRX3wwQd06tSJzp0788orrzBp0qSyTrUc6WceEatSSkOP1N8zd0lqga1bt3Ldddexf/9+jjvuOH76059WuqRDGO6S1AJnnHEGr776aqXLOCpfUJWkDBnukpQhw12SMmS4S1KGfEFVUuv9oHuJx9t9zM2tueUvwKxZs5g4cSJdu3Zt0f4fW7p0KccddxwXXXRRq8YpB8/cJbU7H9/yt6VmzZrF+++/3+o6li5dyrJly1o9TjkY7pLancNv+QswY8YMhg0bxqBBg5g2bRoAf/7znxk9ejTnnHMOAwcO5NFHH2X27Nm8/fbbXHLJJVxyySVHHPuss85i0KBBfO973wMabu97zTXXMGzYMIYNG8avf/1rtmzZwty5c5k5cyaDBw/mV7/6Vdv9AJrAaRlJ7c706dN5/fXXD7wjdPHixWzcuJEVK1aQUmLs2LG89NJL1NfXc+qpp/L00w3vZN+9ezfdu3fnnnvuYcmSJfTu3fuQcXfu3MkTTzzBhg0biAh27doFwK233sp3vvMdvvjFL7J161auuOIK1q9fz7e+9S1OPPHEA08CnyaGu6R2b/HixSxevJhzzz0XgD179rBx40ZGjBjBd7/7XW677TbGjBnDiBEjjjlO9+7dqaqqYsKECYwZM4YxY8YA8Pzzz/PGG28c6Pfuu++yZ8+e8h1QCRjuktq9lBK333473/zmNz+xbfXq1TzzzDN8//vf57LLLuOOO+446jidO3dmxYoVvPDCCyxcuJAf//jHvPjii+zfv5/ly5dTVVVVzsMoqSbPuUdEp4h4NSJ+Waz3i4jfRMSmiHg0Io4r2o8v1jcV22vKVLukDurwW+NeccUVzJ8//8DZ9LZt29i+fTtvv/02Xbt25Wtf+xpTpkxh9erVR9z/Y3v27GH37t2MGjWKmTNnHrgV78iRI5kzZ86Bfh9PB5XyFr2l1pwz91uB9cBJxfq/ADNTSo9ExFxgAnBf8f2dlNLfRMT4ot/flrBmSZ82jVy6WGqH3/J3xowZrF+/ngsvvBCAE088kZ///Ods2rSJKVOm8JnPfIYuXbpw3333AQ0fc1dbW8upp57KkiVLDoz73nvvcdVVV7F3715SStxzzz1Aw6c6TZ48mUGDBrFv3z4uvvhi5s6dy1e+8hXGjRvHU089xZw5cxqd9mlLTbrlb0RUAw8A/wf4J+ArQD3w2ZTSvoi4EPhBSumKiHi2WH4lIjoDfwT6pGM8kLf8ldoXb/nb9pp7y9+mTsvMAv4Z2F+s9wJ2pZQ+/rypOqBvsdwXeAug2L676C9JaiONhntEjAG2p5RWlfKBI2JiRKyMiJX19fWlHFqSOrymnLkPB8ZGxBbgEeBS4F6gRzHtAlANbCuWtwGnARTbuwM7Dx80pTQvpTQ0pTS0T58+rToISW3v0/Apbh1FS37WjYZ7Sun2lFJ1SqkGGA+8mFL6X8ASYFzR7QbgqWJ5UbFOsf3FY823S2p/qqqq2LlzpwHfBlJK7Ny5s9mXYbbmOvfbgEci4i7gVeD+ov1+4MGI2AT8iYYnBEkZqa6upq6uDqdU20ZVVRXV1dXN2qdZ4Z5SWgosLZbfBM4/Qp+9wLXNqkJSu9KlSxf69etX6TJ0DN44TJIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUONhntEVEXEiohYGxHrIuLOor1fRPwmIjZFxKMRcVzRfnyxvqnYXlPmY5AkHaYpZ+4fAJemlM4BBgO1EXEB8C/AzJTS3wDvABOK/hOAd4r2mUU/SVIbajTcU4M9xWqX4isBlwILi/YHgKuL5auKdYrtl0VElKpgSVLjmjTnHhGdImINsB14DtgM7Eop7Su61AF9i+W+wFsAxfbdQK8jjDkxIlZGxMr6+vpWHYQk6VBNCveU0kcppcFANXA+8D9a+8AppXkppaEppaF9+vRp7XCSpIM062qZlNIuYAlwIdAjIjoXm6qBbcXyNuA0gGJ7d2BnKYqVJDVNU66W6RMRPYrlvwIuB9bTEPLjim43AE8Vy4uKdYrtL6aUUglrliQ1onPjXTgFeCAiOtHwZLAgpfTLiHgDeCQi7gJeBe4v+t8PPBgRm4A/AePLULck6RgaDfeU0m+Bc4/Q/iYN8++Ht+8Fri1JdZKkFvEdqpKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRlqNNwj4rSIWBIRb0TEuoi4tWj/64h4LiI2Ft97Fu0REbMjYlNE/DYiziv3QUiSDtWUM/d9wHdTSmcBFwCTI+IsYCrwQkrpDOCFYh3gSuCM4msicF/Jq5YkHVOj4Z5S+kNKaXWx/B6wHugLXAU8UHR7ALi6WL4K+FlqsBzoERGnlLpwSdLRNWvOPSJqgHOB3wAnp5T+UGz6I3BysdwXeOug3eqKtsPHmhgRKyNiZX19fXPrliQdQ5PDPSJOBB4D/jGl9O7B21JKCUjNeeCU0ryU0tCU0tA+ffo0Z1dJUiOaFO4R0YWGYH8opfR40fzfH0+3FN+3F+3bgNMO2r26aJMktZGmXC0TwP3A+pTSPQdtWgTcUCzfADx1UPvfF1fNXADsPmj6RpLUBjo3oc9w4OvAaxGxpmj738B0YEFETAB+D1xXbHsGGAVsAt4HbiplwZKkxjUa7imll4E4yubLjtA/AZNbWZckqRV8h6okZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKUOdKF9BaW6r+rhm9d5etDkn6NPHMXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGWo0XCPiPkRsT0iXj+o7a8j4rmI2Fh871m0R0TMjohNEfHbiDivnMVLko6sKWfu/xeoPaxtKvBCSukM4IViHeBK4IziayJwX2nKlCQ1R6NvYkopvRQRNYc1XwV8qVh+AFgK3Fa0/yyllIDlEdEjIk5JKf2hZBW3Qs3Up5vUb8v00WWuRJLKq6Vz7icfFNh/BE4ulvsCbx3Ur65o+4SImBgRKyNiZX19fQvLkCQdSatfUC3O0lML9puXUhqaUhrap0+f1pYhSTpIS8P9vyPiFIDi+/aifRtw2kH9qos2SVIbamm4LwJuKJZvAJ46qP3vi6tmLgB2f1rm2yWpI2n0BdWI+HcaXjztHRF1wDRgOrAgIiYAvweuK7o/A4wCNgHvAzeVoWZJUiOacrXM9UfZdNkR+iZgcmuLkiS1ju9QlaQMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDDX6DtWOqKn3fQfv/S7p08kzd0nKkOEuSRky3CUpQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJkuEtShvywjlZq6gd7+KEektpShwr3LVV/16R+NXsfLvlj++lOktqS0zKSlCHDXZIy1KGmZdoL5/EltZZn7pKUIc/c2zFfpJV0NIa7DuEThpQHp2UkKUOeubdSJa+dl6SjMdyPoKmB3Z40Z7ql1GM6fSO1vbKEe0TUAvcCnYB/SylNL8fjtCfNecLI7SzfeXyp7ZU83COiE/CvwOVAHfCfEbEopfRGqR8rV+X4y6GpTxiVfhIqx18D5firpal8slKllOPM/XxgU0rpTYCIeAS4CjDcM1PJ6auaqU1/Yqnkk2WzxizHNNcPujex3+4mD1nJJ+Bm/Vs245iaqj1NRUZKqbQDRowDalNK3yjWvw78z5TSPxzWbyIwsVg9E/ivFj5kb2BHC/dtrzzmjsFj7hhac8yfSyn1OdKGir2gmlKaB8xr7TgRsTKlNLQEJbUbHnPH4DF3DOU65nJc574NOO2g9eqiTZLURsoR7v8JnBER/SLiOGA8sKgMjyNJOoqST8uklPZFxD8Az9JwKeT8lNK6Uj/OQVo9tdMOecwdg8fcMZTlmEv+gqokqfK8t4wkZchwl6QMtetwj4jaiPiviNgUEVMrXU+5RcT8iNgeEa9Xupa2EhGnRcSSiHgjItZFxK2VrqncIqIqIlZExNrimO+sdE1tISI6RcSrEfHLStfSFiJiS0S8FhFrImJlycdvr3PuxW0OfsdBtzkArs/5NgcRcTGwB/hZSmlgpetpCxFxCnBKSml1RHQDVgFXZ/7vHMAJKaU9EdEFeBm4NaW0vMKllVVE/BMwFDgppTSm0vWUW0RsAYamlMrypq32fOZ+4DYHKaX/B3x8m4NspZReAv5U6TraUkrpDyml1cXye8B6oG9lqyqv1GBPsdql+GqfZ2FNFBHVwGjg3ypdSy7ac7j3Bd46aL2OzP/Td3QRUQOcC/ymwqWUXTFFsQbYDjyXUsr9mGcB/wzsr3AdbSkBiyNiVXE7lpJqz+GuDiQiTgQeA/4xpfRupespt5TSRymlwTS8w/v8iMh2Gi4ixgDbU0qrKl1LG/tiSuk84EpgcjHtWjLtOdy9zUEHUcw7PwY8lFJ6vNL1tKWU0i5gCVBb4VLKaTgwtpiDfgS4NCJ+XtmSyi+ltK34vh14goap5pJpz+HubQ46gOLFxfuB9SmleypdT1uIiD4R0aNY/isaLhrYUNGiyiildHtKqTqlVEPD/+MXU0pfq3BZZRURJxQXCBARJwAjgZJeBdduwz2ltA/4+DYH64EFZb7NQcVFxL8DrwBnRkRdREyodE1tYDjwdRrO5tYUX6MqXVSZnQIsiYjf0nAS81xKqUNcHtiBnAy8HBFrgRXA0yml/yjlA7TbSyElSUfXbs/cJUlHZ7hLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDP1/PhoHP8uLuRMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 5, 30)\n",
    "\n",
    "plt.hist(y_train, bins, label='training set')\n",
    "plt.hist(y_test, bins, label='test set')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_train, bins, label='training set')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_test, bins, label='test set')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4a586",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "613f939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바꿀 값\n",
    "epochs = 180\n",
    "weight_decay = 0.01\n",
    "lr = 1e-03\n",
    "optim_class = optim.AdamW\n",
    "dim = 256  # 128\n",
    "depth = 4  # 8,12,16,20\n",
    "patch_size = 1  # 2,4,8\n",
    "kernel_size = 3  # 3,5,7,9,11\n",
    "# dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f117c66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhei-jung\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jhj/Desktop/HJ_RESEARCH/snu_brain_disease/wandb/run-20230315_205357-2hk5b1o1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hei-jung/20230314-ConvMixer/runs/2hk5b1o1\" target=\"_blank\">super-deluge-1</a></strong> to <a href=\"https://wandb.ai/hei-jung/20230314-ConvMixer\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 1 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [08:47<00:00,  1.69s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:22<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 2 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:25<00:00,  1.81s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 3 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:09<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 4 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 5 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 6 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 7 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:08<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 8 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 9 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:07<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 10 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:09<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 11 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 12 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 13 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 14 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 15 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 16 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:09<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 17 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 18 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 19 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:09<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 20 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:14<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 21 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 22 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 23 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 24 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:14<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 25 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 26 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:14<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 27 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:09<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 28 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 29 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 30 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 31 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:09<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 32 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 33 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 34 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 35 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 36 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:14<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 37 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 38 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 39 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 40 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:14<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 41 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:09<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 42 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 43 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:15<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 44 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:14<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 45 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:08<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 46 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 47 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 48 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 49 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 50 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 51 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 52 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 53 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:15<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 54 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 55 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 56 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 57 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 58 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 59 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 60 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:08<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 61 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 62 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:08<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 63 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:15<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 64 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:14<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 65 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 66 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 67 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 68 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 69 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 70 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 71 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 72 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 73 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 74 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 75 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:08<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 76 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 77 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 78 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 79 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 80 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 81 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 82 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 83 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:08<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 84 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:12<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 85 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 86 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 87 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:09<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 88 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.78s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 89 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:13<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:24<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 90 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:08<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 91 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:11<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 92 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:10<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 93 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 312/312 [09:09<00:00,  1.76s/it]\n",
      "100%|███████████████████████████████████████████| 78/78 [00:23<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Epoch 94 / 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████▌                 | 179/312 [05:22<03:59,  1.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m train_set\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     39\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_set, batch_size\u001b[38;5;241m=\u001b[39mtest_batch_size, sampler\u001b[38;5;241m=\u001b[39mvalid_sampler, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m preds_t, truths_t, mse_t, mae_t \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m preds_v, truths_v, mse_v, mae_v \u001b[38;5;241m=\u001b[39m valid(model, valid_loader)\n\u001b[1;32m     44\u001b[0m train_p, _ \u001b[38;5;241m=\u001b[39m pearsonr(preds_t, truths_t)\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# weight update\u001b[39;00m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 28\u001b[0m total_mae \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m total_mse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mse\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     31\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 5-Fold cross validation\n",
    "set_seed()\n",
    "splits = KFold(n_splits=k, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(splits.split(np.arange(len(train_set)))):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    set_seed()\n",
    "    model = ConvMixer(h=dim, depth=depth, kernel_size=kernel_size, patch_size=patch_size)\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "    model.cuda()\n",
    "    \n",
    "    wandb.init(project='20230314-ConvMixer',\n",
    "               config={\"model\": f\"ConvMixer-{dim}/{depth}\", \n",
    "                       \"patch_size\": patch_size, \"kernel_size\": kernel_size,\n",
    "                       \"start_lr\": lr, \"weight_decay\": weight_decay, \"epochs\": epochs, \"batch_size\": batch_size,\n",
    "                       \"cost_function\": \"mse_loss\", \"optimizer\": optim_class.__name__, \"fold\": fold+1})\n",
    "    wandb.watch(model)\n",
    "\n",
    "    criterion1 = nn.MSELoss()\n",
    "    criterion2 = nn.L1Loss()\n",
    "\n",
    "    optimizer = optim_class(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    set_seed()\n",
    "    for epoch in range(epochs):\n",
    "        print('# Epoch %d / %d'%(epoch + 1, epochs))\n",
    "        \n",
    "        # train set\n",
    "        augment = get_augmentation_transform()\n",
    "        train_set.transform = augment\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, sampler=train_sampler, num_workers=16)\n",
    "\n",
    "        # validation set\n",
    "        train_set.transform = None\n",
    "        valid_loader = DataLoader(train_set, batch_size=test_batch_size, sampler=valid_sampler, num_workers=16)\n",
    "        \n",
    "        preds_t, truths_t, mse_t, mae_t = train(model, train_loader, optimizer)\n",
    "        preds_v, truths_v, mse_v, mae_v = valid(model, valid_loader)\n",
    "\n",
    "        train_p, _ = pearsonr(preds_t, truths_t)\n",
    "        train_s, _ = spearmanr(preds_t, truths_t)\n",
    "        train_mae = mae_t / len(train_loader)\n",
    "        train_mse = mse_t / len(train_loader)\n",
    "\n",
    "        valid_p, _ = pearsonr(preds_v, truths_v)\n",
    "        valid_s, _ = spearmanr(preds_v, truths_v)\n",
    "        valid_mae = mae_v / len(valid_loader)\n",
    "        valid_mse = mse_v / len(valid_loader)\n",
    "        \n",
    "        wandb.log({\"train_mae\": train_mae, \"train_mse\": train_mse, \"valid_mae\": valid_mae, \"valid_mse\": valid_mse,\n",
    "                   \"train_pearson\": train_p, \"train_spearman\": train_s, \"valid_pearson\": valid_p, \"valid_spearman\": valid_s,})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1d7e6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ConvMixer(\n",
       "    (embed): Sequential(\n",
       "      (0): Conv3d(1, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (1): GELU()\n",
       "      (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv_mixer): Sequential(\n",
       "      (mixer_1): Sequential(\n",
       "        (0): Residual(\n",
       "          (fn): Sequential(\n",
       "            (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, groups=256)\n",
       "            (1): GELU()\n",
       "            (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (2): GELU()\n",
       "        (3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (mixer_2): Sequential(\n",
       "        (0): Residual(\n",
       "          (fn): Sequential(\n",
       "            (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, groups=256)\n",
       "            (1): GELU()\n",
       "            (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (2): GELU()\n",
       "        (3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (mixer_3): Sequential(\n",
       "        (0): Residual(\n",
       "          (fn): Sequential(\n",
       "            (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, groups=256)\n",
       "            (1): GELU()\n",
       "            (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (2): GELU()\n",
       "        (3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (mixer_4): Sequential(\n",
       "        (0): Residual(\n",
       "          (fn): Sequential(\n",
       "            (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=same, groups=256)\n",
       "            (1): GELU()\n",
       "            (2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (2): GELU()\n",
       "        (3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avg_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (linear): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48403a13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바꿀 값\n",
    "epochs = 150\n",
    "weight_decay = 0.01\n",
    "lr = 1e-03\n",
    "optim_class = optim.AdamW\n",
    "dropout_rate = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a6910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold cross validation\n",
    "set_seed()\n",
    "splits = KFold(n_splits=k, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(splits.split(np.arange(len(train_set)))):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    set_seed()\n",
    "    model = MLP(dropout_p=dropout_rate)\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "    model.cuda()\n",
    "    \n",
    "    wandb.init(project='20230309-MLP',\n",
    "               config={\"model\": \"MLP-1\", \"dropout\": dropout_rate,\n",
    "                       \"start_lr\": lr, \"weight_decay\": weight_decay, \"epochs\": epochs, \"batch_size\": batch_size,\n",
    "                       \"cost_function\": \"mse_loss\", \"optimizer\": optim_class.__name__, \"fold\": fold+1})\n",
    "    wandb.watch(model)\n",
    "\n",
    "    criterion1 = nn.MSELoss()\n",
    "    criterion2 = nn.L1Loss()\n",
    "\n",
    "    optimizer = optim_class(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    set_seed()\n",
    "    for epoch in range(epochs):\n",
    "        print('# Epoch %d / %d'%(epoch + 1, epochs))\n",
    "        \n",
    "        # train set\n",
    "        augment = get_augmentation_transform()\n",
    "        train_set.transform = augment\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, sampler=train_sampler, num_workers=16)\n",
    "\n",
    "        # validation set\n",
    "        train_set.transform = None\n",
    "        valid_loader = DataLoader(train_set, batch_size=test_batch_size, sampler=valid_sampler, num_workers=16)\n",
    "        \n",
    "        preds_t, truths_t, mse_t, mae_t = train(model, train_loader, optimizer)\n",
    "        preds_v, truths_v, mse_v, mae_v = valid(model, test_loader)\n",
    "\n",
    "        train_p, _ = pearsonr(preds_t, truths_t)\n",
    "        train_s, _ = spearmanr(preds_t, truths_t)\n",
    "        train_mae = mae_t / len(train_loader)\n",
    "        train_mse = mse_t / len(train_loader)\n",
    "\n",
    "        valid_p, _ = pearsonr(preds_v, truths_v)\n",
    "        valid_s, _ = spearmanr(preds_v, truths_v)\n",
    "        valid_mae = mae_v / len(test_loader)\n",
    "        valid_mse = mse_v / len(test_loader)\n",
    "        \n",
    "        wandb.log({\"train_mae\": train_mae, \"train_mse\": train_mse, \"valid_mae\": valid_mae, \"valid_mse\": valid_mse,\n",
    "                   \"train_pearson\": train_p, \"train_spearman\": train_s, \"valid_pearson\": valid_p, \"valid_spearman\": valid_s,})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e735636",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바꿀 값\n",
    "epochs = 70\n",
    "weight_decay = 0.01\n",
    "lr = 1e-03\n",
    "optim_class = optim.AdamW\n",
    "dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold cross validation\n",
    "set_seed()\n",
    "splits = KFold(n_splits=k, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(splits.split(np.arange(len(train_set)))):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    set_seed()\n",
    "    model = MLP(dropout_p=dropout_rate)\n",
    "    model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "    model.cuda()\n",
    "    \n",
    "    wandb.init(project='20230309-MLP',\n",
    "               config={\"model\": \"MLP-1\", \"dropout\": dropout_rate,\n",
    "                       \"start_lr\": lr, \"weight_decay\": weight_decay, \"epochs\": epochs, \"batch_size\": batch_size,\n",
    "                       \"cost_function\": \"mse_loss\", \"optimizer\": optim_class.__name__, \"fold\": fold+1})\n",
    "    wandb.watch(model)\n",
    "\n",
    "    criterion1 = nn.MSELoss()\n",
    "    criterion2 = nn.L1Loss()\n",
    "\n",
    "    optimizer = optim_class(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    set_seed()\n",
    "    for epoch in range(epochs):\n",
    "        print('# Epoch %d / %d'%(epoch + 1, epochs))\n",
    "        \n",
    "        # train set\n",
    "        augment = get_augmentation_transform()\n",
    "        train_set.transform = augment\n",
    "        train_loader = DataLoader(train_set, batch_size=batch_size, sampler=train_sampler, num_workers=16)\n",
    "\n",
    "        # validation set\n",
    "        train_set.transform = None\n",
    "        valid_loader = DataLoader(train_set, batch_size=test_batch_size, sampler=valid_sampler, num_workers=16)\n",
    "        \n",
    "        preds_t, truths_t, mse_t, mae_t = train(model, train_loader, optimizer)\n",
    "        preds_v, truths_v, mse_v, mae_v = valid(model, test_loader)\n",
    "\n",
    "        train_p, _ = pearsonr(preds_t, truths_t)\n",
    "        train_s, _ = spearmanr(preds_t, truths_t)\n",
    "        train_mae = mae_t / len(train_loader)\n",
    "        train_mse = mse_t / len(train_loader)\n",
    "\n",
    "        valid_p, _ = pearsonr(preds_v, truths_v)\n",
    "        valid_s, _ = spearmanr(preds_v, truths_v)\n",
    "        valid_mae = mae_v / len(test_loader)\n",
    "        valid_mse = mse_v / len(test_loader)\n",
    "        \n",
    "        wandb.log({\"train_mae\": train_mae, \"train_mse\": train_mse, \"valid_mae\": valid_mae, \"valid_mse\": valid_mse,\n",
    "                   \"train_pearson\": train_p, \"train_spearman\": train_s, \"valid_pearson\": valid_p, \"valid_spearman\": valid_s,})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d7d2b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524016a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 바꿀 값\n",
    "epochs = 70\n",
    "weight_decay = 0.01\n",
    "lr = 1e-03\n",
    "optim_class = optim.AdamW\n",
    "sched_class = optim.lr_scheduler.ReduceLROnPlateau\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a05d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MLP(dropout_p=dropout_rate)\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.cuda()\n",
    "\n",
    "wandb.init(project='20230309-MLP',\n",
    "           config={\"model\": \"MLP-1\", \"dropout\": dropout_rate,\n",
    "                   \"start_lr\": lr, \"weight_decay\": weight_decay, \"epochs\": epochs, \"batch_size\": batch_size,\n",
    "                   \"cost_function\": \"mse_loss\", \"optimizer\": optim_class.__name__, \n",
    "                   \"scheduler\": sched_class.__name__, \"start_lr\": lr})\n",
    "wandb.watch(model)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.L1Loss()\n",
    "\n",
    "optimizer = optim_class(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = sched_class(optimizer, mode='min', patience=5, min_lr=0)\n",
    "\n",
    "best_mae, best_mse = 100, 100\n",
    "\n",
    "set_seed()\n",
    "for epoch in range(epochs):\n",
    "    print('# Epoch %d / %d'%(epoch + 1, epochs))\n",
    "\n",
    "    # train set\n",
    "    augment = get_augmentation_transform()\n",
    "    train_set = NeckDataset(X_train, y_train, transform=augment)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=16)\n",
    "\n",
    "    # validation set\n",
    "\n",
    "    preds_t, truths_t, mse_t, mae_t = train(model, train_loader, optimizer)\n",
    "    preds_v, truths_v, mse_v, mae_v = valid(model, test_loader)\n",
    "    \n",
    "    scheduler.step(mse_v)\n",
    "    last_lr = scheduler._last_lr[0]\n",
    "\n",
    "    train_p, _ = pearsonr(preds_t, truths_t)\n",
    "    train_s, _ = spearmanr(preds_t, truths_t)\n",
    "    train_mae = mae_t / len(train_loader)\n",
    "    train_mse = mse_t / len(train_loader)\n",
    "\n",
    "    valid_p, _ = pearsonr(preds_v, truths_v)\n",
    "    valid_s, _ = spearmanr(preds_v, truths_v)\n",
    "    valid_mae = mae_v / len(test_loader)\n",
    "    valid_mse = mse_v / len(test_loader)\n",
    "    \n",
    "    if best_mse > valid_mse:\n",
    "        torch.save(model.state_dict(), 'pretrained/230313_mlp1+mse_{}_w{}_slr{}_bestmse'.format(sched_class.__name__, weight_decay, lr))\n",
    "        best_mse = valid_mse\n",
    "    if best_mae > valid_mae:\n",
    "        torch.save(model.state_dict(), 'pretrained/230313_mlp1+mse_{}_w{}_slr{}_bestmae'.format(sched_class.__name__, weight_decay, lr))\n",
    "        best_mae = valid_mae\n",
    "\n",
    "    wandb.log({\"train_mae\": train_mae, \"train_mse\": train_mse, \"valid_mae\": valid_mae, \"valid_mse\": valid_mse,\n",
    "               \"train_pearson\": train_p, \"train_spearman\": train_s, \"valid_pearson\": valid_p, \"valid_spearman\": valid_s,\n",
    "               \"lr\": last_lr})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea88b82",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bc5e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 바꿀 값\n",
    "epochs = 70\n",
    "weight_decay = 0.01\n",
    "lr = 1e-03\n",
    "optim_class = optim.AdamW\n",
    "sched_class = optim.lr_scheduler.ReduceLROnPlateau\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "model = MLP(dropout_p=dropout_rate, h=[512,256,128,64,32])\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.cuda()\n",
    "\n",
    "wandb.init(project='20230309-MLP',\n",
    "           config={\"model\": \"MLP-2\", \"dropout\": dropout_rate,\n",
    "                   \"start_lr\": lr, \"weight_decay\": weight_decay, \"epochs\": epochs, \"batch_size\": batch_size,\n",
    "                   \"cost_function\": \"mse_loss\", \"optimizer\": optim_class.__name__, \n",
    "                   \"scheduler\": sched_class.__name__, \"start_lr\": lr})\n",
    "wandb.watch(model)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.L1Loss()\n",
    "\n",
    "optimizer = optim_class(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = sched_class(optimizer, mode='min', patience=5, min_lr=0)\n",
    "\n",
    "best_mae, best_mse = 100, 100\n",
    "\n",
    "set_seed()\n",
    "for epoch in range(epochs):\n",
    "    print('# Epoch %d / %d'%(epoch + 1, epochs))\n",
    "\n",
    "    # train set\n",
    "    augment = get_augmentation_transform()\n",
    "    train_set = NeckDataset(X_train, y_train, transform=augment)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=16)\n",
    "\n",
    "    # validation set\n",
    "\n",
    "    preds_t, truths_t, mse_t, mae_t = train(model, train_loader, optimizer)\n",
    "    preds_v, truths_v, mse_v, mae_v = valid(model, test_loader)\n",
    "    \n",
    "    scheduler.step(mse_v)\n",
    "    last_lr = scheduler._last_lr[0]\n",
    "\n",
    "    train_p, _ = pearsonr(preds_t, truths_t)\n",
    "    train_s, _ = spearmanr(preds_t, truths_t)\n",
    "    train_mae = mae_t / len(train_loader)\n",
    "    train_mse = mse_t / len(train_loader)\n",
    "\n",
    "    valid_p, _ = pearsonr(preds_v, truths_v)\n",
    "    valid_s, _ = spearmanr(preds_v, truths_v)\n",
    "    valid_mae = mae_v / len(test_loader)\n",
    "    valid_mse = mse_v / len(test_loader)\n",
    "    \n",
    "    if best_mse > valid_mse:\n",
    "        torch.save(model.state_dict(), 'pretrained/230313_mlp2+mse_{}_w{}_slr{}_bestmse'.format(sched_class.__name__, weight_decay, lr))\n",
    "        best_mse = valid_mse\n",
    "    if best_mae > valid_mae:\n",
    "        torch.save(model.state_dict(), 'pretrained/230313_mlp2+mse_{}_w{}_slr{}_bestmae'.format(sched_class.__name__, weight_decay, lr))\n",
    "        best_mae = valid_mae\n",
    "\n",
    "    wandb.log({\"train_mae\": train_mae, \"train_mse\": train_mse, \"valid_mae\": valid_mae, \"valid_mse\": valid_mse,\n",
    "               \"train_pearson\": train_p, \"train_spearman\": train_s, \"valid_pearson\": valid_p, \"valid_spearman\": valid_s,\n",
    "               \"lr\": last_lr})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec36424",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "weight_decay = 0.01\n",
    "lr = 1e-03\n",
    "optim_class = optim.AdamW\n",
    "# sched_class = optim.lr_scheduler.ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a86db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "set_seed()\n",
    "train_set = NeckDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, num_workers=16)\n",
    "\n",
    "model = MLP()\n",
    "model = torch.nn.DataParallel(model, device_ids=[0, 1])\n",
    "model.cuda()\n",
    "\n",
    "wandb.init(project='20230201-learningrate',\n",
    "           config={\"model\": \"sfcn\", \"dropout\": dropout_rate,\n",
    "                   \"lr\": lr, \"weight_decay\": weight_decay, \"epochs\": epochs, \"batch_size\": batch_size,\n",
    "                   \"cost_function\": \"mse_loss\", \"optimizer\": \"AdamW\", \"fold\": fold+1})\n",
    "wandb.watch(model)\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.L1Loss()\n",
    "\n",
    "optimizer = optim_class(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "set_seed()\n",
    "for epoch in range(epochs):\n",
    "    print('# Epoch %d / %d'%(epoch + 1, epochs))   \n",
    "    preds_t, truths_t, mse_t, mae_t = train(model, train_loader, optimizer)\n",
    "    preds_v, truths_v, mse_v, mae_v = valid(model, test_loader)\n",
    "\n",
    "    train_p, _ = pearsonr(preds_t, truths_t)\n",
    "    train_s, _ = spearmanr(preds_t, truths_t)\n",
    "    train_mae = mae_t / len(train_loader)\n",
    "    train_mse = mse_t / len(train_loader)\n",
    "\n",
    "    valid_p, _ = pearsonr(preds_v, truths_v)\n",
    "    valid_s, _ = spearmanr(preds_v, truths_v)\n",
    "    valid_mae = mae_v / len(test_loader)\n",
    "    valid_mse = mse_v / len(test_loader)\n",
    "\n",
    "    wandb.log({\"train_mae\": train_mae, \"train_mse\": train_mse, \"valid_mae\": valid_mae, \"valid_mse\": valid_mse,\n",
    "       \"train_pearson\": train_p, \"train_spearman\": train_s, \"valid_pearson\": valid_p, \"valid_spearman\": valid_s,})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba474024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def predict(model, data_loader, title='', line=False):\n",
    "    model.eval()\n",
    "    preds, truths = np.array([]), np.array([])\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader):\n",
    "            inputs, labels = inputs.to(device, dtype=torch.float), labels.to(device, dtype=torch.float)\n",
    "            output = model(inputs)\n",
    "            pred = output.detach().cpu().numpy()\n",
    "            truth = labels.detach().cpu().numpy()\n",
    "            preds = np.append(preds, pred.reshape(pred.size), axis=0)\n",
    "            truths = np.append(truths, truth.reshape(truth.size), axis=0)\n",
    "        \n",
    "    # Get correlation coefficients\n",
    "    pearson, pearson_p = pearsonr(preds, truths)\n",
    "    spearman, spearman_p = spearmanr(preds, truths)\n",
    "    \n",
    "    # For range setting\n",
    "    _min = y_min - 0.5\n",
    "    _max = y_max + 0.5\n",
    "    \n",
    "    # Figure size\n",
    "#     plt.figure(figsize=(5, 5))\n",
    "    \n",
    "    # Reference line\n",
    "    x = np.linspace(_min, _max)\n",
    "    y = x\n",
    "    plt.plot(x, y, c='gray', ls='--', label='Reference r = 1.0')\n",
    "    \n",
    "    # Regression Plot\n",
    "    \n",
    "    ## Scatter\n",
    "    plt.scatter(truths, preds, c='steelblue', label='Pearson\\'s r = {:.2f} / Spearman\\'s r = {:.2f}'.format(pearson,spearman))\n",
    "    \n",
    "    ## Linear Regression Line\n",
    "    if line:\n",
    "        m, b = np.polyfit(truths, preds, 1)\n",
    "        plt.plot(truths, m*truths + b, c='steelblue', label='m = {:.2f}'.format(m))\n",
    "#     # Regression Plot at once\n",
    "#     sns.regplot(x=truths, y=preds, ci=None, color='steelblue', label='Pearson r = {:.2f}'.format(pearson))\n",
    "\n",
    "    if title != '':\n",
    "        plt.title(title)\n",
    "    \n",
    "    plt.axis('square')\n",
    "    plt.ylabel('Predicted WMH'); plt.xlabel('Ground Truth')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.xlim([_min, _max])\n",
    "    plt.ylim([_min, _max])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    return preds, truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f495f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_min, y_max =y_test.min(), y_test.max()\n",
    "y_min, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c8f9c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_,_ = predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fcf45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SFCN()\n",
    "net.load_state_dict(torch.load('pretrained/230131_sfcn+mae_best'))\n",
    "net.to(device)\n",
    "_,_ = predict(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0a3066",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NeckDataset(train_X, train_y)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, num_workers=16)\n",
    "_,_ = predict(model, train_loader, 'Training set')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
